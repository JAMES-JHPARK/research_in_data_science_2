{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return (\"{:0>2}:{:0>2}:{:0>2}\".format(int(hours),int(minutes),int(seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = (preds>0.5)\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def confusion_matrix_(y, preds):\n",
    "    rounded_preds = (preds>0.5)\n",
    "    cm = confusion_matrix(y, rounded_preds).ravel()\n",
    "    return cm\n",
    "\n",
    "def f1_score_(y, preds):\n",
    "    rounded_preds = (preds>0.5)\n",
    "    f1 = f1_score(y, rounded_preds)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy_flow(preds, y, flow):\n",
    "    rounded_preds = rounded_preds_by_flow(preds, y, flow)\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def confusion_matrix_flow(y, preds, flow):\n",
    "    rounded_preds = rounded_preds_by_flow(preds, y, flow).cpu().detach().numpy()\n",
    "    cm = confusion_matrix(y, rounded_preds).ravel()\n",
    "    return cm\n",
    "\n",
    "def f1_score_flow(y, preds, flow):\n",
    "    rounded_preds = rounded_preds_by_flow(preds, y, flow).cpu().detach().numpy()\n",
    "    f1 = f1_score(y, rounded_preds)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_preds_by_flow(preds, y, flow):\n",
    "    rounded_preds = (preds>0.5).float()\n",
    "    cnt = []\n",
    "    for i in range(len(flow)-1):\n",
    "        if flow[i] != flow[i+1]:\n",
    "            cnt.append(i+1)\n",
    "    for i in range(len(cnt)-1):    \n",
    "        if rounded_preds[cnt[i]:cnt[i+1]].mean() > 0.5:\n",
    "            rounded_preds[cnt[i]:cnt[i+1]] = 1\n",
    "        else:\n",
    "            rounded_preds[cnt[i]:cnt[i+1]] = 0\n",
    "        #print(rounded_preds[cnt[i]:cnt[i+1]], y[cnt[i]:cnt[i+1]], flow[cnt[i]:cnt[i+1]], '\\n')\n",
    "        \n",
    "    return rounded_preds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.pk', 'rb') as f:\n",
    "    dataset = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.asarray(dataset, dtype=np.int64)\n",
    "\n",
    "# train : validation : test = 8 : 1 : 1\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, stratify=dataset[:,33], random_state=1)\n",
    "test_data, validation_data = train_test_split(test_data, test_size=0.5, stratify=test_data[:,33], random_state=1)\n",
    "\n",
    "train_data = pd.DataFrame(train_data).sort_values(by=34)\n",
    "test_data = pd.DataFrame(test_data).sort_values(by=34)\n",
    "validation_data = pd.DataFrame(validation_data).sort_values(by=34)\n",
    "\n",
    "train_data = np.asarray(train_data, dtype=np.int64)\n",
    "test_data = np.asarray(test_data, dtype=np.int64)\n",
    "validation_data = np.asarray(validation_data, dtype=np.int64)\n",
    "\n",
    "train_label = train_data[:, 33]\n",
    "test_label = test_data[:, 33]\n",
    "train_flow = train_data[:, 34]\n",
    "test_flow = test_data[:, 34]\n",
    "train_data = train_data[:, :33]\n",
    "test_data = test_data[:, :33]\n",
    "\n",
    "train_data, train_label, train_flow = np.array(train_data), np.array(train_label), np.array(train_flow)\n",
    "test_data, test_label, test_flow = np.array(test_data), np.array(test_label), np.array(test_flow)\n",
    "\n",
    "train_data, train_label, train_flow = torch.Tensor(train_data), torch.Tensor(train_label), torch.Tensor(train_flow)\n",
    "test_data, test_label, test_flow = torch.Tensor(test_data), torch.Tensor(test_label), torch.Tensor(test_flow)\n",
    "\n",
    "train_data = TensorDataset(train_data, train_label, train_flow)\n",
    "test_data = TensorDataset(test_data, test_label, test_flow)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout, batch_size):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.embed = nn.Embedding(num_embeddings = 0xffff+1, embedding_dim=64)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)\n",
    "        out, (hn, cn) = self.lstm(emb)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "num_layers = 3\n",
    "dropout = 0.2\n",
    "batch_size = 100\n",
    "\n",
    "model = LSTMmodel(input_dim, hidden_dim, num_layers, output_dim, dropout, batch_size).to(device)\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    epoch_f1_score = 0.0\n",
    "    \n",
    "    epoch_tn = 0.0\n",
    "    epoch_fp = 0.0\n",
    "    epoch_fn = 0.0\n",
    "    epoch_tp = 0.0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for x_, y_, flow in iterator:\n",
    "        x_ = x_.long()\n",
    "        y_ = y_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_.to(device)).reshape(-1)\n",
    "        loss = criterion(preds, y_)\n",
    "        acc = binary_accuracy(preds, y_)\n",
    "        cm = confusion_matrix_(y_.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "        f1 = f1_score_(y_.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        epoch_f1_score += f1\n",
    "        \n",
    "        if len(cm)==1:\n",
    "            cm = np.append(cm, 0)\n",
    "            cm = np.append(cm, 0)\n",
    "            cm = np.append(cm, 0)\n",
    "        \n",
    "        epoch_tn += cm[0]\n",
    "        epoch_fp += cm[1]\n",
    "        epoch_fn += cm[2]\n",
    "        epoch_tp += cm[3]\n",
    "        \n",
    "    return epoch_loss/len(train_data), epoch_acc/len(train_data), epoch_f1_score/len(iterator), epoch_tn, epoch_fp, epoch_fn, epoch_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    epoch_f1_score = 0.0\n",
    "\n",
    "    epoch_tn = 0.0\n",
    "    epoch_fp = 0.0\n",
    "    epoch_fn = 0.0\n",
    "    epoch_tp = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_, y_, _ in iterator:\n",
    "            x_ = x_.long()\n",
    "            y_ = y_.to(device)\n",
    "            preds = model(x_.to(device)).reshape(-1)\n",
    "            loss = criterion(preds, y_)\n",
    "            acc = binary_accuracy(preds, y_)\n",
    "            cm = confusion_matrix_(y_.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "            f1 = f1_score_(y_.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            epoch_f1_score += f1\n",
    "            \n",
    "            if len(cm)==1:\n",
    "                cm = np.append(cm, 0)\n",
    "                cm = np.append(cm, 0)\n",
    "                cm = np.append(cm, 0)\n",
    "                \n",
    "            epoch_tn += cm[0]\n",
    "            epoch_fp += cm[1]\n",
    "            epoch_fn += cm[2]\n",
    "            epoch_tp += cm[3]\n",
    "        \n",
    "    return epoch_loss/len(test_data), epoch_acc/len(test_data), epoch_f1_score/len(iterator), epoch_tn, epoch_fp, epoch_fn, epoch_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_flow(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    epoch_f1_score = 0.0\n",
    "\n",
    "    epoch_tn = 0.0\n",
    "    epoch_fp = 0.0\n",
    "    epoch_fn = 0.0\n",
    "    epoch_tp = 0.0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x_, y_, flow in iterator:\n",
    "            x_ = x_.long()\n",
    "            y_ = y_.to(device)\n",
    "\n",
    "            preds = model(x_.to(device)).reshape(-1)\n",
    "            loss = criterion(preds, y_)\n",
    "            acc = binary_accuracy_flow(preds, y_, flow)\n",
    "            cm = confusion_matrix_flow(y_.cpu().detach().numpy(), preds, flow)\n",
    "            f1 = f1_score_flow(y_.cpu().detach().numpy(), preds, flow)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            epoch_f1_score += f1\n",
    "            \n",
    "            if len(cm)==1:\n",
    "                cm = np.append(cm, 0)\n",
    "                cm = np.append(cm, 0)\n",
    "                cm = np.append(cm, 0)\n",
    "                \n",
    "            epoch_tn += cm[0]\n",
    "            epoch_fp += cm[1]\n",
    "            epoch_fn += cm[2]\n",
    "            epoch_tp += cm[3]\n",
    "        \n",
    "    return epoch_loss/len(test_data), epoch_acc/len(test_data), epoch_f1_score/len(iterator), epoch_tn, epoch_fp, epoch_fn, epoch_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN Process\n",
    "\n",
    "n_epochs = 20\n",
    "start_time = time.time()\n",
    "\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []\n",
    "\n",
    "train_f1_hist = []\n",
    "train_tn_hist = []\n",
    "train_fp_hist = []\n",
    "train_fn_hist = []\n",
    "train_tp_hist = []\n",
    "\n",
    "test_f1_hist = []\n",
    "test_tn_hist = []\n",
    "test_fp_hist = []\n",
    "test_fn_hist = []\n",
    "test_tp_hist = []\n",
    "\n",
    "train_cm_hist = []\n",
    "test_cm_hist = []\n",
    "\n",
    "train_cm = np.zeros((2, 2))\n",
    "test_cm = np.zeros((2, 2)) \n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    train_loss, train_acc, train_f1, train_tn, train_fp, train_fn, train_tp = train(model, train_loader, optimizer, criterion)\n",
    "    test_loss, test_acc, test_f1, test_tn, test_fp, test_fn, test_tp = evaluate(model, test_loader, criterion)\n",
    "\n",
    "    train_loss_hist.append(train_loss)\n",
    "    train_acc_hist.append(train_acc)\n",
    "    test_loss_hist.append(test_loss)\n",
    "    test_acc_hist.append(test_acc)\n",
    "    \n",
    "    train_f1_hist.append(train_f1)\n",
    "    test_f1_hist.append(test_f1)\n",
    "\n",
    "    train_cm_hist.append((train_tn, train_fp, train_fn, train_tp))\n",
    "    test_cm_hist.append((test_tn, test_fp, test_fn, test_tp))\n",
    "    \n",
    "    torch.save(model, 'Results/epoch_{}.model'.format(epoch))\n",
    "    \n",
    "    print('| Epoch : {:02} | Elapsed time : {} | Train Loss : {:.6f} | Train Acc : {:.2f}% | Test Loss : {:.6f} | Test Acc : {:.2f}% |'\n",
    "          .format(epoch+1, timer(start_time, time.time()), train_loss, train_acc*100, test_loss, test_acc*100))\n",
    "    print('| Train f-1 : {:.6f} | Test f-1 : {:.6f} |'.format(train_f1, test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(20)],train_acc_hist[0:20])\n",
    "plt.plot([i for i in range(20)],test_acc_hist[0:20])\n",
    "plt.plot([i for i in range(20)],test_acc_hist2[0:20])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,20))\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(['Training_Accuracy','Validation_Accuracy(by packet)', 'Validation_Accuracy(by flow)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "con_mat = np.zeros([2,2], dtype = np.int)\n",
    "con_mat[0][0] = test_tn\n",
    "con_mat[0][1] = test_fp\n",
    "con_mat[1][0] = test_fn\n",
    "con_mat[1][1] = test_tp\n",
    "\n",
    "plt.imshow(con_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "label=[\"Benign(0)\", \"Malicious(1)\"] # 라벨값\n",
    "tick_marks = np.arange(len(label)) \n",
    "plt.xticks(tick_marks, label)\n",
    "plt.yticks(tick_marks, label)\n",
    "plt.xlabel('Predicted', fontsize=15)\n",
    "plt.ylabel('True', fontsize=15)\n",
    "# 표 안에 숫자 기입하는 방법\n",
    "name = [['TP','FN'], ['FP', 'TN']]\n",
    "thresh = con_mat.max() / 2.\n",
    "for i in range(2):\n",
    "     for j in range(2):\n",
    "        plt.text(j, i, str(name[i][j])+\" = \"+str(con_mat[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if con_mat[i, j] > thresh else \"black\",\n",
    "                 fontsize=16)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_label = validation_data[:, 33]\n",
    "testset_flow = validation_data[:, 34]\n",
    "testset_data = validation_data[:, :33]\n",
    "\n",
    "testset_data = np.array(testset_data)\n",
    "testset_label = np.array(testset_label)\n",
    "testset_flow = np.array(testset_flow)\n",
    "\n",
    "testset_data, testset_label, testset_flow = torch.Tensor(testset_data), torch.Tensor(testset_label), torch.Tensor(testset_flow)\n",
    "\n",
    "testset_data = TensorDataset(testset_data, testset_label, testset_flow)\n",
    "\n",
    "testset_loader = DataLoader(testset_data, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Results/epoch_8.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_f1, test_tn, test_fp, test_fn, test_tp = evaluate(model, testset_loader, criterion)\n",
    "print('Test loss : {}, Test Acc : {}, Test F1 : {}'.format(test_loss, test_acc, test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_f1, test_tn, test_fp, test_fn, test_tp = evaluate_flow(model, testset_loader, criterion)\n",
    "print('Test loss : {}, Test Acc : {}, Test F1 : {}'.format(test_loss, test_acc, test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def train_calibrated(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    epoch_f1_score = 0.0\n",
    "    \n",
    "    epoch_tn = 0.0\n",
    "    epoch_fp = 0.0\n",
    "    epoch_fn = 0.0\n",
    "    epoch_tp = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    preds_array = []\n",
    "    y_array = []\n",
    "    \n",
    "    for x_, y_ in iterator:\n",
    "        x_ = x_.long()\n",
    "        y_ = y_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(x_.to(device)).reshape(-1)\n",
    "        preds_array = np.append(preds_array, preds.cpu().detach().numpy())\n",
    "        y_array = np.append(y_array, y_.cpu().detach().numpy())\n",
    "\n",
    "    return y_array, preds_array\n",
    "   \n",
    "model = torch.load('Result/iscx-33-8epoch.model')\n",
    "y_array, preds_array = train_calibrated(model, train_loader, optimizer, criterion)\n",
    "\n",
    "prob_y, prob_preds = calibration_curve(y_array, preds_array, n_bins=10)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(prob_preds, prob_y, marker='.')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
